Search.setIndex({"docnames": ["index"], "filenames": ["index.rst"], "titles": ["Welcome to Noisy Entropy Estimation\u2019s documentation!"], "terms": {"index": 0, "modul": 0, "search": 0, "page": 0, "author": 0, "sim\u00e9on": 0, "ferez": 0, "version": 0, "1": 0, "0": 0, "copyright": 0, "2023": 0, "all": 0, "right": 0, "reserv": 0, "thi": 0, "work": 0, "mai": 0, "reproduc": 0, "whole": 0, "part": 0, "without": 0, "written": 0, "permiss": 0, "credit": 0, "tweetnlp": 0, "cut": 0, "edg": 0, "natur": 0, "languag": [], "process": 0, "social": 0, "media": 0, "camacho": 0, "collado": 0, "j": 0, "rezae": 0, "k": 0, "riahi": 0, "t": 0, "ushio": 0, "A": 0, "loureiro": 0, "d": 0, "antypa": 0, "boisson": 0, "espinosa": 0, "ank": 0, "l": 0, "liu": 0, "f": 0, "martinez": 0, "c\u00e1mara": 0, "e": 0, "other": 0, "2022": 0, "appli": 0, "nlp": [], "emot": [], "detect": 0, "twitter": 0, "csv": 0, "file": 0, "anger": [], "anticip": [], "disgust": [], "2": 0, "fear": [], "3": 0, "joi": [], "4": 0, "love": 0, "5": 0, "optim": [], "6": [], "pessim": [], "7": [], "sad": [], "8": [], "surpris": [], "9": 0, "trust": [], "10": 0, "detect_emot": [], "text": 0, "batch_siz": [], "64": [], "list": 0, "us": 0, "model": 0, "return": 0, "correspond": 0, "label": 0, "id": 0, "param": [], "type": 0, "batch": [], "size": 0, "int": 0, "rtype": [], "i": 0, "am": 0, "so": 0, "happi": 0, "main": 0, "function": 0, "script": 0, "none": 0, "process_fil": 0, "fp": 0, "save": 0, "path": 0, "str": 0, "data": 0, "process_file_chunk": 0, "num_lin": 0, "chunk": 0, "number": 0, "line": 0, "100_000": 0, "hate": 0, "speech": [], "non": [], "hatespeech": [], "detect_h": [], "you": 0, "ar": 0, "ugli": [], "result": 0, "same": 0, "load": 0, "datafram": 0, "create_df": [], "process_hr": 0, "hrate_dir": 0, "hrate": [], "The": 0, "directori": 0, "contain": 0, "panda": 0, "hrate_data": 0, "process_label": 0, "label_typ": 0, "get": 0, "correct": 0, "name": 0, "process_multiple_analysi": 0, "main_dir": 0, "multipl": 0, "analys": 0, "sentiment": [], "topic": [], "offens": [], "date": 0, "ironi": [], "order": 0, "ppm_entropi": 0, "ppm_infor_cont": 0, "ppm_model_ord": 0, "ppm_distribut": 0, "unigram_data": 0, "tupl": 0, "process_ppm": 0, "ppm_dir": 0, "ppm": [], "process_single_analysi": 0, "singl": 0, "elonmusk": 0, "process_unigram": 0, "unigram_dir": 0, "unigram": 0, "perform": 0, "preliminari": 0, "code": 0, "preliminary_analysis_cod": [], "analyse_ppm": 0, "ppm_file": 0, "fals": 0, "whether": 0, "plot": 0, "bool": 0, "txt": 0, "analyse_token": 0, "token_fil": 0, "token": 0, "is_punctu": 0, "check": 0, "punctuat": 0, "symbol": 0, "true": 0, "otherwis": 0, "is_special_token": 0, "special": 0, "var": 0, "plot_token_frequ": 0, "df": 0, "vocab_s": 0, "percentag": 0, "fall": 0, "each": 0, "categori": 0, "frequenc": 0, "pd": 0, "vocabulari": 0, "b": 0, "c": 0, "count": 0, "run_code_analysi": 0, "run": 0, "preliminary_analysis_text": [], "run_text_analysi": 0, "tweet": 0, "preliminary_analysis_tweet": [], "general_inform": 0, "print": 0, "gener": 0, "inform": 0, "about": 0, "load_data": 0, "from": 0, "given": 0, "map_senti": 0, "map": 0, "an": 0, "integ": 0, "neutral": 0, "plot_by_dai": 0, "dai": 0, "week": 0, "plot_distribution_label": 0, "distribut": 0, "plot_sentiment_over_tim": 0, "averag": 0, "over": 0, "time": 0, "plot_tweets_over_tim": 0, "run_tweet_analysi": 0, "tweets_per_us": 0, "statist": 0, "per": 0, "user": 0, "dehydr": 0, "keep": 0, "onli": 0, "tweet_id": 0, "dehydrate_tweet": [], "py": [], "scweet": 0, "extens": 0, "toolbox": 0, "scrape": [], "python": 0, "environ": 0, "variabl": 0, "env": [], "get_access_token": 0, "access": 0, "get_access_token_secret": 0, "secret": 0, "get_bearer_token": 0, "bearer": 0, "get_chromedriver_path": 0, "chromedriv": 0, "get_consumer_kei": 0, "consum": 0, "kei": 0, "get_consumer_secret": 0, "get_email": 0, "email": 0, "get_password": 0, "password": 0, "get_usernam": 0, "usernam": 0, "load_env_vari": 0, "default_valu": 0, "none_allow": 0, "default": 0, "valu": 0, "found": 0, "can": 0, "test": 0, "hydrat": 0, "hydrate_tweet": [], "seleniu": 0, "creat": 0, "run_scrap": [], "sampl": 0, "stream": 0, "api": 0, "v2": 0, "gather": 0, "real": 0, "base": 0, "filter": 0, "sample_stream": [], "bearer_oauth": 0, "r": 0, "method": 0, "requir": 0, "authent": 0, "request": 0, "check_dat": 0, "ha": 0, "chang": 0, "close": 0, "current": 0, "open": 0, "new": 0, "one": 0, "connect_to_endpoint": 0, "url": 0, "connect": 0, "endpoint": 0, "http": 0, "com": 0, "field": 0, "lang": 0, "created_at": 0, "expans": 0, "author_id": 0, "place": 0, "create_url": 0, "covid": 0, "github": 0, "public": 0, "repositori": 0, "rehydr": 0, "twarc": 0, "scrape_covid_github": [], "sinc": 0, "until": 0, "word": 0, "to_account": 0, "from_account": 0, "mention_account": 0, "interv": 0, "headless": 0, "limit": 0, "inf": 0, "display_typ": 0, "top": 0, "resum": 0, "proxi": 0, "hashtag": 0, "save_dir": 0, "output": 0, "filter_repli": 0, "proxim": 0, "geocod": 0, "minrepli": 0, "minlik": 0, "minretweet": 0, "driver": 0, "only_id": 0, "paramet": 0, "which": 0, "we": 0, "start": 0, "account": 0, "between": 0, "two": 0, "mode": 0, "displai": 0, "previou": 0, "repli": 0, "minimum": 0, "like": 0, "retweet": 0, "selenium": 0, "webdriv": 0, "2020": 0, "01": 0, "02": 0, "corona": 0, "util": [], "check_exists_by_xpath": 0, "xpath": 0, "element": 0, "exist": 0, "chrome": 0, "check_for_error": 0, "error": 0, "rate": 0, "exceed": 0, "get_data": 0, "card": 0, "extract": 0, "remot": 0, "webel": 0, "If": 0, "post": 0, "123456789": 0, "2021": 0, "01t00": 0, "00": 0, "000z": 0, "get_last_date_from_csv": 0, "last": 0, "get_metadata": 0, "twarc_sess": 0, "metadata": 0, "session": 0, "get_pag": 0, "retri": 0, "wait_tim": 0, "wait": 0, "q": 0, "get_user_id": 0, "arg": 0, "kwarg": 0, "wrapper": 0, "memoiz": 0, "argument": 0, "dict": 0, "keyword": 0, "ani": 0, "init_driv": 0, "show_imag": 0, "option": 0, "initi": 0, "firefoxdriv": 0, "instanc": 0, "show": 0, "imag": 0, "add": 0, "keep_scrol": 0, "writer": 0, "scroll": 0, "tweet_pars": 0, "last_posit": 0, "crawl": 0, "set": 0, "pars": 0, "posit": 0, "log_in": 0, "timeout": 0, "20": 0, "log": 0, "log_search_pag": 0, "until_loc": 0, "To": 0, "mention": 0, "func": 0, "avoid": 0, "recomput": 0, "leverag": 0, "cach": 0, "full": 0, "project": 0, "includ": 0, "full_analysi": [], "run_hrate_entropi": 0, "run_ppm_entropi": 0, "vocab": 0, "run_unigram_entropi": 0, "corpu": 0, "nsb_entropi": 0, "june": 0, "2011": 0, "sungho": 0, "hong": 0, "comput": 0, "neurosci": 0, "unit": 0, "okinawa": 0, "institut": 0, "scienc": 0, "technologi": 0, "2019": 0, "updat": 0, "charli": 0, "strauss": 0, "lo": 0, "alamo": 0, "nation": 0, "lab": 0, "mathematica": 0, "christian": 0, "mendl": 0, "implement": 0, "nemenman": 0, "shafe": 0, "bialek": 0, "nsb": 0, "For": 0, "detail": 0, "out": 0, "refer": 0, "below": 0, "It": 0, "depend": 0, "mpmath": 0, "numpi": 0, "packag": 0, "net": 0, "softwar": 0, "html": 0, "sourceforg": 0, "ilya": 0, "fariel": 0, "william": 0, "infer": 0, "revisit": 0, "arxiv": 0, "physic": 0, "0108025": 0, "rob": 0, "de": 0, "ruyter": 0, "van": 0, "steveninck": 0, "neural": 0, "spike": 0, "train": 0, "progress": 0, "problem": 0, "review": 0, "69": 0, "056111": 0, "2004": 0, "nxkx": 0, "n": 0, "histogram": 0, "input": 0, "construct": 0, "make_nxkx": 0, "total": 0, "degre": 0, "freedom": 0, "import": 0, "arrai": 0, "ntest": 0, "actual": 0, "equal": 0, "sum": 0, "940646728502697166844598206814653716492": 0, "mean": 0, "squar": 0, "flucuat": 0, "sqrt": 0, "np": 0, "790453283682443237187782792251041316212": 0, "standard": 0, "deviat": 0, "1560242251518078487118059349690693094484": 0, "assum": 0, "bin": 0, "run_dir": [], "run_nsb": [], "calcul": 0, "counter": 0, "std": 0, "float": 0, "all_token": 0, "english": 0, "en": 0, "french": 0, "fr": 0, "german": 0, "italian": 0, "spanish": 0, "detect_languag": 0, "lingua": 0, "iso": 0, "639": 0, "column": 0, "clean": 0, "allow": 0, "remov": 0, "string": 0, "comment": 0, "clean_cod": [], "tsv": 0, "rm_comment": 0, "replac": 0, "them": 0, "def": 0, "hello": 0, "rm_number": 0, "num": 0, "x": 0, "rm_string": 0, "rm_variables_and_func": 0, "clean_tweet": [], "give_emoji_free_text": 0, "emoji": 0, "librari": 0, "remove_acc": 0, "accent": 0, "unidecod": 0, "ceci": 0, "est": 0, "un": 0, "r\u00e9sum\u00e9": 0, "remove_emoji": 0, "regex": 0, "remove_emoticon": 0, "emoticon": 0, "remove_extra_spac": 0, "extra": 0, "space": 0, "remove_ment": 0, "remove_punctu": 0, "remove_rt": 0, "rt": 0, "remove_twitter_url": 0, "remove_url": 0, "pic": 0, "123": 0, "www": 0, "googl": 0, "to_lowercas": 0, "convert": 0, "lowercas": 0, "combin": [], "combine_metadata": [], "combine_vocab": [], "specifi": 0, "filter_languag": [], "raw": 0, "dataset": 0, "generate_metadata": [], "sub": 0, "group": 0, "generate_sub_df": [], "ad": 0, "class": 0, "labelled_data": 0, "program": 0, "tokenize_cod": [], "generate_ngram": 0, "gram": 0, "tokenize_tweet": [], "linguist": 0, "tokenize_text": [], "namedent": [], "command": [], "interfac": [], "java": 0, "debug": 0, "v": 0, "exampl": 0, "cli": 0, "o": 0, "p": 0, "m": 0, "u": 0, "tag": 0, "case": 0, "final": 0, "final_vocab": 0, "gb": 0, "timestamp": 0, "choos": 0, "month": 0, "y": 0, "year": 0, "min": 0, "100": 0, "1000": 0, "class_": 0, "char": 0, "charact": 0, "level": 0, "ngram": 0, "instead": 0, "fast": 0, "fa": 0, "forc": 0, "fo": 0, "descript": 0, "where": 0, "want": 0, "credenti": 0, "consumer_kei": 0, "consumer_secret": 0, "access_token": 0, "access_token_secret": 0, "end": 0, "todai": 0, "h": 0, "w": 0, "collect": 0, "python3": 0, "31": 0, "bitcoin": 0, "ukrain": 0, "iter_max": 0, "maximum": 0, "1_000_000": 0, "format": 0, "yyyi": 0, "mm": 0, "dd": 0, "03": 0, "22": 0, "max": 0, "04": 0, "12": 0, "500_000": 0, "23": 0, "provid": 0, "consid": 0, "use_vocab": 0, "uv": 0, "skip": 0, "uncertainti": 0, "output_dir": 0, "file_nam": 0, "src": 0, "max_token": 0, "algorithm": 0, "100000": 0, "max_train": 0, "decai": 0, "5000": 0, "input_dir": 0, "analyz": 0, "decript": 0, "dsecript": 0}, "objects": {"": [[0, 0, 0, "-", "Hrate"], [0, 0, 0, "-", "clean_code"], [0, 0, 0, "-", "clean_tweets"], [0, 0, 0, "-", "combine"], [0, 0, 0, "-", "combine_metadata"], [0, 0, 0, "-", "combine_vocab"], [0, 0, 0, "-", "create_df"], [0, 0, 0, "-", "dehydrate_tweets"], [0, 0, 0, "-", "env"], [0, 0, 0, "-", "filter_language"], [0, 0, 0, "-", "full_analysis"], [0, 0, 0, "-", "generate_metadata"], [0, 0, 0, "-", "generate_sub_df"], [0, 0, 0, "-", "hydrate_tweets"], [0, 0, 0, "-", "labelled_data"], [0, 0, 0, "-", "languages"], [0, 0, 0, "-", "nsb"], [0, 0, 0, "-", "ppm"], [0, 0, 0, "-", "preliminary_analysis_code"], [0, 0, 0, "-", "preliminary_analysis_text"], [0, 0, 0, "-", "preliminary_analysis_tweet"], [0, 0, 0, "-", "run_dir"], [0, 0, 0, "-", "run_nsb"], [0, 0, 0, "-", "run_scraping"], [0, 0, 0, "-", "sample_stream"], [0, 0, 0, "-", "scrape_covid_github"], [0, 0, 0, "-", "scraping"], [0, 0, 0, "-", "tokenize_code"], [0, 0, 0, "-", "tokenize_text"], [0, 0, 0, "-", "tokenize_tweets"], [0, 0, 0, "-", "utils"]], "Hrate": [[0, 1, 1, "", "main"]], "clean_code": [[0, 1, 1, "", "main"], [0, 1, 1, "", "process_file"], [0, 1, 1, "", "rm_comments"], [0, 1, 1, "", "rm_numbers"], [0, 1, 1, "", "rm_strings"], [0, 1, 1, "", "rm_variables_and_func"]], "clean_tweets": [[0, 1, 1, "", "give_emoji_free_text"], [0, 1, 1, "", "main"], [0, 1, 1, "", "process_file"], [0, 1, 1, "", "remove_accents"], [0, 1, 1, "", "remove_emoji"], [0, 1, 1, "", "remove_emoticons"], [0, 1, 1, "", "remove_extra_spaces"], [0, 1, 1, "", "remove_mentions"], [0, 1, 1, "", "remove_punctuation"], [0, 1, 1, "", "remove_rt"], [0, 1, 1, "", "remove_twitter_urls"], [0, 1, 1, "", "remove_urls"], [0, 1, 1, "", "to_lowercase"]], "combine": [[0, 1, 1, "", "main"]], "combine_metadata": [[0, 1, 1, "", "main"]], "combine_vocab": [[0, 1, 1, "", "main"]], "create_df": [[0, 1, 1, "", "process_hrate"], [0, 1, 1, "", "process_label"], [0, 1, 1, "", "process_multiple_analysis"], [0, 1, 1, "", "process_ppm"], [0, 1, 1, "", "process_single_analysis"], [0, 1, 1, "", "process_unigrams"]], "dehydrate_tweets": [[0, 1, 1, "", "main"], [0, 1, 1, "", "process_file"]], "env": [[0, 1, 1, "", "get_access_token"], [0, 1, 1, "", "get_access_token_secret"], [0, 1, 1, "", "get_bearer_token"], [0, 1, 1, "", "get_chromedriver_path"], [0, 1, 1, "", "get_consumer_key"], [0, 1, 1, "", "get_consumer_secret"], [0, 1, 1, "", "get_email"], [0, 1, 1, "", "get_password"], [0, 1, 1, "", "get_username"], [0, 1, 1, "", "load_env_variable"]], "filter_language": [[0, 1, 1, "", "main"], [0, 1, 1, "", "process_file"]], "full_analysis": [[0, 1, 1, "", "main"], [0, 1, 1, "", "run_hrate_entropy"], [0, 1, 1, "", "run_ppm_entropy"], [0, 1, 1, "", "run_unigram_entropy"]], "generate_metadata": [[0, 1, 1, "", "main"]], "generate_sub_df": [[0, 1, 1, "", "main"], [0, 1, 1, "", "process_file"]], "hydrate_tweets": [[0, 1, 1, "", "main"], [0, 1, 1, "", "process_file"]], "labelled_data": [[0, 1, 1, "", "main"], [0, 1, 1, "", "process_file"]], "languages": [[0, 1, 1, "", "detect_language"], [0, 1, 1, "", "main"], [0, 1, 1, "", "process_file"]], "nsb": [[0, 1, 1, "", "S"], [0, 1, 1, "", "dS"], [0, 1, 1, "", "make_nxkx"]], "ppm": [[0, 1, 1, "", "main"]], "preliminary_analysis_code": [[0, 1, 1, "", "analyse_ppm"], [0, 1, 1, "", "analyse_tokens"], [0, 1, 1, "", "is_punctuation"], [0, 1, 1, "", "is_special_token"], [0, 1, 1, "", "plot_token_frequencies"], [0, 1, 1, "", "run_code_analysis"]], "preliminary_analysis_text": [[0, 1, 1, "", "analyse_tokens"], [0, 1, 1, "", "is_punctuation"], [0, 1, 1, "", "plot_token_frequencies"], [0, 1, 1, "", "run_text_analysis"]], "preliminary_analysis_tweet": [[0, 1, 1, "", "analyse_ppm"], [0, 1, 1, "", "analyse_tokens"], [0, 1, 1, "", "general_informations"], [0, 1, 1, "", "is_punctuation"], [0, 1, 1, "", "load_data"], [0, 1, 1, "", "map_sentiment"], [0, 1, 1, "", "plot_by_day"], [0, 1, 1, "", "plot_distribution_label"], [0, 1, 1, "", "plot_sentiment_over_time"], [0, 1, 1, "", "plot_token_frequencies"], [0, 1, 1, "", "plot_tweets_over_time"], [0, 1, 1, "", "run_tweet_analysis"], [0, 1, 1, "", "tweets_per_user"]], "run_dir": [[0, 1, 1, "", "main"]], "run_nsb": [[0, 1, 1, "", "main"], [0, 1, 1, "", "nsb_entropy"], [0, 1, 1, "", "process_file"]], "run_scraping": [[0, 1, 1, "", "main"]], "sample_stream": [[0, 1, 1, "", "bearer_oauth"], [0, 1, 1, "", "check_date"], [0, 1, 1, "", "connect_to_endpoint"], [0, 1, 1, "", "create_url"], [0, 1, 1, "", "main"]], "scrape_covid_github": [[0, 1, 1, "", "main"]], "scraping": [[0, 1, 1, "", "scraping"]], "tokenize_code": [[0, 1, 1, "", "generate_ngrams"], [0, 1, 1, "", "main"], [0, 1, 1, "", "process_file"], [0, 1, 1, "", "process_file_chunk"]], "tokenize_text": [[0, 1, 1, "", "generate_ngrams"], [0, 1, 1, "", "main"], [0, 1, 1, "", "process_file"]], "tokenize_tweets": [[0, 1, 1, "", "generate_ngrams"], [0, 1, 1, "", "main"], [0, 1, 1, "", "process_file"], [0, 1, 1, "", "process_file_chunk"]], "utils": [[0, 1, 1, "", "check_exists_by_xpath"], [0, 1, 1, "", "check_for_error"], [0, 1, 1, "", "get_data"], [0, 1, 1, "", "get_last_date_from_csv"], [0, 1, 1, "", "get_metadata"], [0, 1, 1, "", "get_page"], [0, 1, 1, "", "get_user_id"], [0, 1, 1, "", "init_driver"], [0, 1, 1, "", "keep_scroling"], [0, 1, 1, "", "log_in"], [0, 1, 1, "", "log_search_page"], [0, 1, 1, "", "memoize"]]}, "objtypes": {"0": "py:module", "1": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "function", "Python function"]}, "titleterms": {"welcom": 0, "noisi": 0, "entropi": 0, "estim": 0, "": 0, "document": 0, "indic": 0, "tabl": 0, "analysi": 0, "data": [], "acquisit": [], "nlp": 0, "preprocess": 0, "create_df": 0, "py": 0, "preliminary_analysis_cod": 0, "preliminary_analysis_text": 0, "preliminary_analysis_tweet": 0, "dataacquisit": 0, "dehydrate_tweet": 0, "env": 0, "hydrate_tweet": 0, "run_scrap": 0, "sample_stream": 0, "scrape_covid_github": 0, "scrape": 0, "util": 0, "entropyestim": 0, "full_analysi": 0, "hrate": 0, "nse": 0, "ppm": 0, "run_dir": 0, "run_nsb": 0, "clean_cod": 0, "clean_tweet": 0, "combin": 0, "combine_metadata": 0, "combine_vocab": 0, "filter_languag": 0, "generate_metadata": 0, "generate_sub_df": 0, "labeled_data": 0, "tokenize_cod": 0, "tokenize_tweet": 0, "tokenize_text": 0, "emot": 0, "hatespeech": 0, "ironi": 0, "languag": 0, "namedent": 0, "offens": 0, "sentiment": 0, "topic": 0}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 60}, "alltitles": {"Welcome to Noisy Entropy Estimation\u2019s documentation!": [[0, "welcome-to-noisy-entropy-estimation-s-documentation"]], "Analysis/create_df.py": [[0, "analysis-create-df-py"]], "Analysis/preliminary_analysis_code.py": [[0, "analysis-preliminary-analysis-code-py"]], "Analysis/preliminary_analysis_text.py": [[0, "analysis-preliminary-analysis-text-py"]], "Analysis/preliminary_analysis_tweet.py": [[0, "analysis-preliminary-analysis-tweet-py"]], "DataAcquisition/dehydrate_tweets.py": [[0, "dataacquisition-dehydrate-tweets-py"]], "DataAcquisition/env.py": [[0, "dataacquisition-env-py"]], "DataAcquisition/hydrate_tweets.py": [[0, "dataacquisition-hydrate-tweets-py"]], "DataAcquisition/run_scraping.py": [[0, "dataacquisition-run-scraping-py"]], "DataAcquisition/sample_stream.py": [[0, "dataacquisition-sample-stream-py"]], "DataAcquisition/scrape_covid_github.py": [[0, "dataacquisition-scrape-covid-github-py"]], "DataAcquisition/scraping.py": [[0, "dataacquisition-scraping-py"]], "DataAcquisition/utils.py": [[0, "dataacquisition-utils-py"]], "EntropyEstimation/entropy.py": [[0, "entropyestimation-entropy-py"]], "EntropyEstimation/full_analysis.py": [[0, "entropyestimation-full-analysis-py"]], "EntropyEstimation/Hrate.py": [[0, "entropyestimation-hrate-py"]], "EntropyEstimation/nse.py": [[0, "entropyestimation-nse-py"]], "EntropyEstimation/ppm.py": [[0, "entropyestimation-ppm-py"]], "EntropyEstimation/run_dir.py": [[0, "entropyestimation-run-dir-py"]], "EntropyEstimation/run_nsb.py": [[0, "entropyestimation-run-nsb-py"]], "NLP/emotion.py": [[0, "nlp-emotion-py"]], "NLP/hateSpeech.py": [[0, "nlp-hatespeech-py"]], "NLP/irony.py": [[0, "nlp-irony-py"]], "NLP/languages.py": [[0, "nlp-languages-py"]], "NLP/namedEntity.py": [[0, "nlp-namedentity-py"]], "NLP/offensive.py": [[0, "nlp-offensive-py"]], "NLP/sentiment.py": [[0, "nlp-sentiment-py"]], "NLP/topic.py": [[0, "nlp-topic-py"]], "Preprocessing/clean_code.py": [[0, "preprocessing-clean-code-py"]], "Preprocessing/clean_tweets.py": [[0, "preprocessing-clean-tweets-py"]], "Preprocessing/combine.py": [[0, "preprocessing-combine-py"]], "Preprocessing/combine_metadata.py": [[0, "preprocessing-combine-metadata-py"]], "Preprocessing/combine_vocab.py": [[0, "preprocessing-combine-vocab-py"]], "Preprocessing/filter_language.py": [[0, "preprocessing-filter-language-py"]], "Preprocessing/generate_metadata.py": [[0, "preprocessing-generate-metadata-py"]], "Preprocessing/generate_sub_df.py": [[0, "preprocessing-generate-sub-df-py"]], "Preprocessing/labeled_data.py": [[0, "preprocessing-labeled-data-py"]], "Preprocessing/tokenize_code.py": [[0, "preprocessing-tokenize-code-py"]], "Preprocessing/tokenize_tweets.py": [[0, "preprocessing-tokenize-tweets-py"]], "Preprocessing/tokenize_text.py": [[0, "preprocessing-tokenize-text-py"]], "Indices and tables": [[0, "indices-and-tables"]]}, "indexentries": {"hrate": [[0, "module-Hrate"]], "s() (in module nsb)": [[0, "nsb.S"]], "analyse_ppm() (in module preliminary_analysis_code)": [[0, "preliminary_analysis_code.analyse_ppm"]], "analyse_ppm() (in module preliminary_analysis_tweet)": [[0, "preliminary_analysis_tweet.analyse_ppm"]], "analyse_tokens() (in module preliminary_analysis_code)": [[0, "preliminary_analysis_code.analyse_tokens"]], "analyse_tokens() (in module preliminary_analysis_text)": [[0, "preliminary_analysis_text.analyse_tokens"]], "analyse_tokens() (in module preliminary_analysis_tweet)": [[0, "preliminary_analysis_tweet.analyse_tokens"]], "bearer_oauth() (in module sample_stream)": [[0, "sample_stream.bearer_oauth"]], "check_date() (in module sample_stream)": [[0, "sample_stream.check_date"]], "check_exists_by_xpath() (in module utils)": [[0, "utils.check_exists_by_xpath"]], "check_for_error() (in module utils)": [[0, "utils.check_for_error"]], "clean_code": [[0, "module-clean_code"]], "clean_tweets": [[0, "module-clean_tweets"]], "combine": [[0, "module-combine"]], "combine_metadata": [[0, "module-combine_metadata"]], "combine_vocab": [[0, "module-combine_vocab"]], "connect_to_endpoint() (in module sample_stream)": [[0, "sample_stream.connect_to_endpoint"]], "create_df": [[0, "module-create_df"]], "create_url() (in module sample_stream)": [[0, "sample_stream.create_url"]], "ds() (in module nsb)": [[0, "nsb.dS"]], "dehydrate_tweets": [[0, "module-dehydrate_tweets"]], "detect_language() (in module languages)": [[0, "languages.detect_language"]], "env": [[0, "module-env"]], "filter_language": [[0, "module-filter_language"]], "full_analysis": [[0, "module-full_analysis"]], "general_informations() (in module preliminary_analysis_tweet)": [[0, "preliminary_analysis_tweet.general_informations"]], "generate_metadata": [[0, "module-generate_metadata"]], "generate_ngrams() (in module tokenize_code)": [[0, "tokenize_code.generate_ngrams"]], "generate_ngrams() (in module tokenize_text)": [[0, "tokenize_text.generate_ngrams"]], "generate_ngrams() (in module tokenize_tweets)": [[0, "tokenize_tweets.generate_ngrams"]], "generate_sub_df": [[0, "module-generate_sub_df"]], "get_access_token() (in module env)": [[0, "env.get_access_token"]], "get_access_token_secret() (in module env)": [[0, "env.get_access_token_secret"]], "get_bearer_token() (in module env)": [[0, "env.get_bearer_token"]], "get_chromedriver_path() (in module env)": [[0, "env.get_chromedriver_path"]], "get_consumer_key() (in module env)": [[0, "env.get_consumer_key"]], "get_consumer_secret() (in module env)": [[0, "env.get_consumer_secret"]], "get_data() (in module utils)": [[0, "utils.get_data"]], "get_email() (in module env)": [[0, "env.get_email"]], "get_last_date_from_csv() (in module utils)": [[0, "utils.get_last_date_from_csv"]], "get_metadata() (in module utils)": [[0, "utils.get_metadata"]], "get_page() (in module utils)": [[0, "utils.get_page"]], "get_password() (in module env)": [[0, "env.get_password"]], "get_user_id() (in module utils)": [[0, "utils.get_user_id"]], "get_username() (in module env)": [[0, "env.get_username"]], "give_emoji_free_text() (in module clean_tweets)": [[0, "clean_tweets.give_emoji_free_text"]], "hydrate_tweets": [[0, "module-hydrate_tweets"]], "init_driver() (in module utils)": [[0, "utils.init_driver"]], "is_punctuation() (in module preliminary_analysis_code)": [[0, "preliminary_analysis_code.is_punctuation"]], "is_punctuation() (in module preliminary_analysis_text)": [[0, "preliminary_analysis_text.is_punctuation"]], "is_punctuation() (in module preliminary_analysis_tweet)": [[0, "preliminary_analysis_tweet.is_punctuation"]], "is_special_token() (in module preliminary_analysis_code)": [[0, "preliminary_analysis_code.is_special_token"]], "keep_scroling() (in module utils)": [[0, "utils.keep_scroling"]], "labelled_data": [[0, "module-labelled_data"]], "languages": [[0, "module-languages"]], "load_data() (in module preliminary_analysis_tweet)": [[0, "preliminary_analysis_tweet.load_data"]], "load_env_variable() (in module env)": [[0, "env.load_env_variable"]], "log_in() (in module utils)": [[0, "utils.log_in"]], "log_search_page() (in module utils)": [[0, "utils.log_search_page"]], "main() (in module hrate)": [[0, "Hrate.main"]], "main() (in module clean_code)": [[0, "clean_code.main"]], "main() (in module clean_tweets)": [[0, "clean_tweets.main"]], "main() (in module combine)": [[0, "combine.main"]], "main() (in module combine_metadata)": [[0, "combine_metadata.main"]], "main() (in module combine_vocab)": [[0, "combine_vocab.main"]], "main() (in module dehydrate_tweets)": [[0, "dehydrate_tweets.main"]], "main() (in module filter_language)": [[0, "filter_language.main"]], "main() (in module full_analysis)": [[0, "full_analysis.main"]], "main() (in module generate_metadata)": [[0, "generate_metadata.main"]], "main() (in module generate_sub_df)": [[0, "generate_sub_df.main"]], "main() (in module hydrate_tweets)": [[0, "hydrate_tweets.main"]], "main() (in module labelled_data)": [[0, "labelled_data.main"]], "main() (in module languages)": [[0, "languages.main"]], "main() (in module ppm)": [[0, "ppm.main"]], "main() (in module run_dir)": [[0, "run_dir.main"]], "main() (in module run_nsb)": [[0, "run_nsb.main"]], "main() (in module run_scraping)": [[0, "run_scraping.main"]], "main() (in module sample_stream)": [[0, "sample_stream.main"]], "main() (in module scrape_covid_github)": [[0, "scrape_covid_github.main"]], "main() (in module tokenize_code)": [[0, "tokenize_code.main"]], "main() (in module tokenize_text)": [[0, "tokenize_text.main"]], "main() (in module tokenize_tweets)": [[0, "tokenize_tweets.main"]], "make_nxkx() (in module nsb)": [[0, "nsb.make_nxkx"]], "map_sentiment() (in module preliminary_analysis_tweet)": [[0, "preliminary_analysis_tweet.map_sentiment"]], "memoize() (in module utils)": [[0, "utils.memoize"]], "module": [[0, "module-Hrate"], [0, "module-clean_code"], [0, "module-clean_tweets"], [0, "module-combine"], [0, "module-combine_metadata"], [0, "module-combine_vocab"], [0, "module-create_df"], [0, "module-dehydrate_tweets"], [0, "module-env"], [0, "module-filter_language"], [0, "module-full_analysis"], [0, "module-generate_metadata"], [0, "module-generate_sub_df"], [0, "module-hydrate_tweets"], [0, "module-labelled_data"], [0, "module-languages"], [0, "module-nsb"], [0, "module-ppm"], [0, "module-preliminary_analysis_code"], [0, "module-preliminary_analysis_text"], [0, "module-preliminary_analysis_tweet"], [0, "module-run_dir"], [0, "module-run_nsb"], [0, "module-run_scraping"], [0, "module-sample_stream"], [0, "module-scrape_covid_github"], [0, "module-scraping"], [0, "module-tokenize_code"], [0, "module-tokenize_text"], [0, "module-tokenize_tweets"], [0, "module-utils"]], "nsb": [[0, "module-nsb"]], "nsb_entropy() (in module run_nsb)": [[0, "run_nsb.nsb_entropy"]], "plot_by_day() (in module preliminary_analysis_tweet)": [[0, "preliminary_analysis_tweet.plot_by_day"]], "plot_distribution_label() (in module preliminary_analysis_tweet)": [[0, "preliminary_analysis_tweet.plot_distribution_label"]], "plot_sentiment_over_time() (in module preliminary_analysis_tweet)": [[0, "preliminary_analysis_tweet.plot_sentiment_over_time"]], "plot_token_frequencies() (in module preliminary_analysis_code)": [[0, "preliminary_analysis_code.plot_token_frequencies"]], "plot_token_frequencies() (in module preliminary_analysis_text)": [[0, "preliminary_analysis_text.plot_token_frequencies"]], "plot_token_frequencies() (in module preliminary_analysis_tweet)": [[0, "preliminary_analysis_tweet.plot_token_frequencies"]], "plot_tweets_over_time() (in module preliminary_analysis_tweet)": [[0, "preliminary_analysis_tweet.plot_tweets_over_time"]], "ppm": [[0, "module-ppm"]], "preliminary_analysis_code": [[0, "module-preliminary_analysis_code"]], "preliminary_analysis_text": [[0, "module-preliminary_analysis_text"]], "preliminary_analysis_tweet": [[0, "module-preliminary_analysis_tweet"]], "process_file() (in module clean_code)": [[0, "clean_code.process_file"]], "process_file() (in module clean_tweets)": [[0, "clean_tweets.process_file"]], "process_file() (in module dehydrate_tweets)": [[0, "dehydrate_tweets.process_file"]], "process_file() (in module filter_language)": [[0, "filter_language.process_file"]], "process_file() (in module generate_sub_df)": [[0, "generate_sub_df.process_file"]], "process_file() (in module hydrate_tweets)": [[0, "hydrate_tweets.process_file"]], "process_file() (in module labelled_data)": [[0, "labelled_data.process_file"]], "process_file() (in module languages)": [[0, "languages.process_file"]], "process_file() (in module run_nsb)": [[0, "run_nsb.process_file"]], "process_file() (in module tokenize_code)": [[0, "tokenize_code.process_file"]], "process_file() (in module tokenize_text)": [[0, "tokenize_text.process_file"]], "process_file() (in module tokenize_tweets)": [[0, "tokenize_tweets.process_file"]], "process_file_chunk() (in module tokenize_code)": [[0, "tokenize_code.process_file_chunk"]], "process_file_chunk() (in module tokenize_tweets)": [[0, "tokenize_tweets.process_file_chunk"]], "process_hrate() (in module create_df)": [[0, "create_df.process_hrate"]], "process_label() (in module create_df)": [[0, "create_df.process_label"]], "process_multiple_analysis() (in module create_df)": [[0, "create_df.process_multiple_analysis"]], "process_ppm() (in module create_df)": [[0, "create_df.process_ppm"]], "process_single_analysis() (in module create_df)": [[0, "create_df.process_single_analysis"]], "process_unigrams() (in module create_df)": [[0, "create_df.process_unigrams"]], "remove_accents() (in module clean_tweets)": [[0, "clean_tweets.remove_accents"]], "remove_emoji() (in module clean_tweets)": [[0, "clean_tweets.remove_emoji"]], "remove_emoticons() (in module clean_tweets)": [[0, "clean_tweets.remove_emoticons"]], "remove_extra_spaces() (in module clean_tweets)": [[0, "clean_tweets.remove_extra_spaces"]], "remove_mentions() (in module clean_tweets)": [[0, "clean_tweets.remove_mentions"]], "remove_punctuation() (in module clean_tweets)": [[0, "clean_tweets.remove_punctuation"]], "remove_rt() (in module clean_tweets)": [[0, "clean_tweets.remove_rt"]], "remove_twitter_urls() (in module clean_tweets)": [[0, "clean_tweets.remove_twitter_urls"]], "remove_urls() (in module clean_tweets)": [[0, "clean_tweets.remove_urls"]], "rm_comments() (in module clean_code)": [[0, "clean_code.rm_comments"]], "rm_numbers() (in module clean_code)": [[0, "clean_code.rm_numbers"]], "rm_strings() (in module clean_code)": [[0, "clean_code.rm_strings"]], "rm_variables_and_func() (in module clean_code)": [[0, "clean_code.rm_variables_and_func"]], "run_code_analysis() (in module preliminary_analysis_code)": [[0, "preliminary_analysis_code.run_code_analysis"]], "run_dir": [[0, "module-run_dir"]], "run_hrate_entropy() (in module full_analysis)": [[0, "full_analysis.run_hrate_entropy"]], "run_nsb": [[0, "module-run_nsb"]], "run_ppm_entropy() (in module full_analysis)": [[0, "full_analysis.run_ppm_entropy"]], "run_scraping": [[0, "module-run_scraping"]], "run_text_analysis() (in module preliminary_analysis_text)": [[0, "preliminary_analysis_text.run_text_analysis"]], "run_tweet_analysis() (in module preliminary_analysis_tweet)": [[0, "preliminary_analysis_tweet.run_tweet_analysis"]], "run_unigram_entropy() (in module full_analysis)": [[0, "full_analysis.run_unigram_entropy"]], "sample_stream": [[0, "module-sample_stream"]], "scrape_covid_github": [[0, "module-scrape_covid_github"]], "scraping": [[0, "module-scraping"]], "scraping() (in module scraping)": [[0, "scraping.scraping"]], "to_lowercase() (in module clean_tweets)": [[0, "clean_tweets.to_lowercase"]], "tokenize_code": [[0, "module-tokenize_code"]], "tokenize_text": [[0, "module-tokenize_text"]], "tokenize_tweets": [[0, "module-tokenize_tweets"]], "tweets_per_user() (in module preliminary_analysis_tweet)": [[0, "preliminary_analysis_tweet.tweets_per_user"]], "utils": [[0, "module-utils"]]}})